"""–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ"""
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
import time
from collections import defaultdict

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.insert(0, str(Path(__file__).parent.parent))

from dotenv import load_dotenv
from app.retriever import RAGRetriever
from app.rag_service import RAGService

load_dotenv()


class RAGEvaluator:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã"""
    
    def __init__(self, retriever: RAGRetriever, rag_service: RAGService):
        self.retriever = retriever
        self.rag_service = rag_service
        self.results = []
    
    def evaluate_retrieval(self, question: str, expected_source: str, expected_topics: List[str]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤"""
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ —Å–∫–æ—Ä–∞–º–∏
        context = self.retriever.get_context_for_query(question, top_k=5, with_scores=True)
        
        documents = context['documents']
        scores = context.get('scores', [])
        sources = context['sources']
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 1: –ù–∞–π–¥–µ–Ω –ª–∏ –æ–∂–∏–¥–∞–µ–º—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫
        source_found = any(expected_source in source['filename'] for source in sources)
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 2: –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º (–≤ —Ç–æ–ø-3)
        top_docs = documents[:3]
        topic_matches = []
        for topic in expected_topics:
            found = any(topic.lower() in doc.page_content.lower() for doc in top_docs)
            topic_matches.append(found)
        
        topic_coverage = sum(topic_matches) / len(expected_topics) if expected_topics else 0
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 3: –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ç–æ–ø-3
        avg_score_top3 = sum(scores[:3]) / 3 if len(scores) >= 3 else (sum(scores) / len(scores) if scores else 1.0)
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 4: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        num_docs = len(documents)
        
        return {
            'source_found': source_found,
            'topic_coverage': topic_coverage,
            'avg_score_top3': avg_score_top3,
            'num_docs_retrieved': num_docs,
            'sources': [s['filename'] for s in sources],
            'scores': scores[:5]  # –¢–æ–ø-5 —Å–∫–æ—Ä–æ–≤
        }
    
    def evaluate_generation(self, question: str, answer: str, expected_topics: List[str]) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
        # –ú–µ—Ç—Ä–∏–∫–∞ 1: –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞ (–∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ—Å—Ç—å)
        answer_length = len(answer)
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 2: –ü–æ–∫—Ä—ã—Ç–∏–µ –æ–∂–∏–¥–∞–µ–º—ã—Ö —Ç–æ–ø–∏–∫–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ
        answer_lower = answer.lower()
        topics_in_answer = sum(1 for topic in expected_topics if topic.lower() in answer_lower)
        topic_coverage_answer = topics_in_answer / len(expected_topics) if expected_topics else 0
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 3: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–Ω–∞–ª–∏—á–∏–µ —Å–ø–∏—Å–∫–æ–≤, –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤)
        has_structure = any(marker in answer for marker in ['\n-', '\n*', '\n1.', '\n2.', '##'])
        
        # –ú–µ—Ç—Ä–∏–∫–∞ 4: –ù–∞–ª–∏—á–∏–µ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        russian_chars = sum(1 for c in answer if '–∞' <= c.lower() <= '—è')
        total_chars = sum(1 for c in answer if c.isalpha())
        russian_ratio = russian_chars / total_chars if total_chars > 0 else 0
        
        return {
            'answer_length': answer_length,
            'topic_coverage_answer': topic_coverage_answer,
            'has_structure': has_structure,
            'russian_ratio': russian_ratio,
            'answer_preview': answer[:200] + '...' if len(answer) > 200 else answer
        }
    
    def evaluate_question(self, question_data: Dict[str, Any], use_hyde: bool = False) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞"""
        question = question_data['question']
        expected_source = question_data.get('expected_source', '')
        expected_topics = question_data.get('expected_topics', [])
        category = question_data.get('category', 'unknown')
        difficulty = question_data.get('difficulty', 'unknown')
        
        print(f"\n{'='*80}")
        print(f"–í–æ–ø—Ä–æ—Å: {question}")
        print(f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category} | –°–ª–æ–∂–Ω–æ—Å—Ç—å: {difficulty}")
        print(f"{'='*80}")
        
        # –û—Ü–µ–Ω–∫–∞ –ø–æ–∏—Å–∫–∞
        print("\nüîç –û—Ü–µ–Ω–∫–∞ –ø–æ–∏—Å–∫–∞...")
        retrieval_metrics = self.evaluate_retrieval(question, expected_source, expected_topics)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        print("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞...")
        start_time = time.time()
        result = self.rag_service.generate_answer(question, top_k=5, use_hyde=use_hyde)
        generation_time = time.time() - start_time
        
        # –û—Ü–µ–Ω–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        print("üìä –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞...")
        generation_metrics = self.evaluate_generation(question, result['answer'], expected_topics)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        evaluation = {
            'question': question,
            'category': category,
            'difficulty': difficulty,
            'expected_source': expected_source,
            'expected_topics': expected_topics,
            'retrieval': retrieval_metrics,
            'generation': generation_metrics,
            'generation_time': generation_time,
            'num_documents_used': result['num_documents_used'],
            'total_tokens_context': result['total_tokens_context'],
            'used_hyde': use_hyde,
            'answer': result['answer']
        }
        
        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print(f"  ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞–π–¥–µ–Ω: {'‚úì' if retrieval_metrics['source_found'] else '‚úó'}")
        print(f"  ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤ (–ø–æ–∏—Å–∫): {retrieval_metrics['topic_coverage']:.1%}")
        print(f"  ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤ (–æ—Ç–≤–µ—Ç): {generation_metrics['topic_coverage_answer']:.1%}")
        print(f"  ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ç–æ–ø-3: {retrieval_metrics['avg_score_top3']:.3f}")
        print(f"  ‚Ä¢ –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {generation_metrics['answer_length']} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  ‚Ä¢ –í—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {generation_time:.2f}s")
        print(f"  ‚Ä¢ –ù–∞–π–¥–µ–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(retrieval_metrics['sources'][:3])}")
        
        return evaluation
    
    def evaluate_dataset(self, dataset_path: str, use_hyde: bool = False) -> Dict[str, Any]:
        """–û—Ü–µ–Ω–∫–∞ –≤—Å–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞"""
        print(f"\n{'#'*80}")
        print(f"# –û–¶–ï–ù–ö–ê RAG –°–ò–°–¢–ï–ú–´ –ù–ê –î–ê–¢–ê–°–ï–¢–ï")
        print(f"# –î–∞—Ç–∞—Å–µ—Ç: {dataset_path}")
        print(f"# HyDE: {'–≤–∫–ª—é—á–µ–Ω' if use_hyde else '–≤—ã–∫–ª—é—á–µ–Ω'}")
        print(f"{'#'*80}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
        with open(dataset_path, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        
        print(f"\nüìö –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(dataset)} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # –û—Ü–µ–Ω–∏–≤–∞–µ–º –∫–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å
        results = []
        for i, question_data in enumerate(dataset, 1):
            print(f"\n\n{'='*80}")
            print(f"–í–û–ü–†–û–° {i}/{len(dataset)}")
            print(f"{'='*80}")
            
            try:
                evaluation = self.evaluate_question(question_data, use_hyde=use_hyde)
                results.append(evaluation)
            except Exception as e:
                print(f"\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {e}")
                results.append({
                    'question': question_data['question'],
                    'error': str(e)
                })
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        print(f"\n\n{'#'*80}")
        print(f"# –ò–¢–û–ì–û–í–´–ï –ú–ï–¢–†–ò–ö–ò")
        print(f"{'#'*80}")
        
        metrics = self.calculate_aggregate_metrics(results)
        self.print_metrics(metrics)
        
        return {
            'results': results,
            'aggregate_metrics': metrics,
            'dataset_size': len(dataset),
            'used_hyde': use_hyde
        }
    
    def calculate_aggregate_metrics(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –º–µ—Ç—Ä–∏–∫"""
        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å –æ—à–∏–±–∫–∞–º–∏
        valid_results = [r for r in results if 'error' not in r]
        
        if not valid_results:
            return {}
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ–∏—Å–∫–∞
        source_found_rate = sum(1 for r in valid_results if r['retrieval']['source_found']) / len(valid_results)
        avg_topic_coverage_retrieval = sum(r['retrieval']['topic_coverage'] for r in valid_results) / len(valid_results)
        avg_score = sum(r['retrieval']['avg_score_top3'] for r in valid_results) / len(valid_results)
        avg_docs_retrieved = sum(r['retrieval']['num_docs_retrieved'] for r in valid_results) / len(valid_results)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        avg_answer_length = sum(r['generation']['answer_length'] for r in valid_results) / len(valid_results)
        avg_topic_coverage_answer = sum(r['generation']['topic_coverage_answer'] for r in valid_results) / len(valid_results)
        structured_answers_rate = sum(1 for r in valid_results if r['generation']['has_structure']) / len(valid_results)
        avg_russian_ratio = sum(r['generation']['russian_ratio'] for r in valid_results) / len(valid_results)
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å
        avg_generation_time = sum(r['generation_time'] for r in valid_results) / len(valid_results)
        avg_tokens = sum(r['total_tokens_context'] for r in valid_results) / len(valid_results)
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        by_category = defaultdict(list)
        for r in valid_results:
            by_category[r['category']].append(r)
        
        category_metrics = {}
        for category, cat_results in by_category.items():
            category_metrics[category] = {
                'count': len(cat_results),
                'source_found_rate': sum(1 for r in cat_results if r['retrieval']['source_found']) / len(cat_results),
                'avg_topic_coverage': sum(r['retrieval']['topic_coverage'] for r in cat_results) / len(cat_results),
                'avg_answer_length': sum(r['generation']['answer_length'] for r in cat_results) / len(cat_results)
            }
        
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        by_difficulty = defaultdict(list)
        for r in valid_results:
            by_difficulty[r['difficulty']].append(r)
        
        difficulty_metrics = {}
        for difficulty, diff_results in by_difficulty.items():
            difficulty_metrics[difficulty] = {
                'count': len(diff_results),
                'source_found_rate': sum(1 for r in diff_results if r['retrieval']['source_found']) / len(diff_results),
                'avg_topic_coverage': sum(r['retrieval']['topic_coverage'] for r in diff_results) / len(diff_results),
                'avg_score': sum(r['retrieval']['avg_score_top3'] for r in diff_results) / len(diff_results)
            }
        
        return {
            'overall': {
                'total_questions': len(results),
                'successful_questions': len(valid_results),
                'failed_questions': len(results) - len(valid_results)
            },
            'retrieval': {
                'source_found_rate': source_found_rate,
                'avg_topic_coverage': avg_topic_coverage_retrieval,
                'avg_score_top3': avg_score,
                'avg_docs_retrieved': avg_docs_retrieved
            },
            'generation': {
                'avg_answer_length': avg_answer_length,
                'avg_topic_coverage': avg_topic_coverage_answer,
                'structured_answers_rate': structured_answers_rate,
                'avg_russian_ratio': avg_russian_ratio
            },
            'performance': {
                'avg_generation_time': avg_generation_time,
                'avg_tokens_context': avg_tokens
            },
            'by_category': category_metrics,
            'by_difficulty': difficulty_metrics
        }
    
    def print_metrics(self, metrics: Dict[str, Any]):
        """–ö—Ä–∞—Å–∏–≤—ã–π –≤—ã–≤–æ–¥ –º–µ—Ç—Ä–∏–∫"""
        if not metrics:
            print("‚ùå –ù–µ—Ç –º–µ—Ç—Ä–∏–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è")
            return
        
        print("\nüìä –û–ë–©–ò–ï –ú–ï–¢–†–ò–ö–ò")
        print("-" * 80)
        overall = metrics['overall']
        print(f"  –í—Å–µ–≥–æ –≤–æ–ø—Ä–æ—Å–æ–≤: {overall['total_questions']}")
        print(f"  –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {overall['successful_questions']}")
        print(f"  –û—à–∏–±–æ–∫: {overall['failed_questions']}")
        
        print("\nüîç –ú–ï–¢–†–ò–ö–ò –ü–û–ò–°–ö–ê")
        print("-" * 80)
        retrieval = metrics['retrieval']
        print(f"  –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞–π–¥–µ–Ω: {retrieval['source_found_rate']:.1%}")
        print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤: {retrieval['avg_topic_coverage']:.1%}")
        print(f"  –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä —Ç–æ–ø-3: {retrieval['avg_score_top3']:.3f}")
        print(f"  –°—Ä–µ–¥–Ω–µ–µ –∫–æ–ª-–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {retrieval['avg_docs_retrieved']:.1f}")
        
        print("\nüìù –ú–ï–¢–†–ò–ö–ò –ì–ï–ù–ï–†–ê–¶–ò–ò")
        print("-" * 80)
        generation = metrics['generation']
        print(f"  –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {generation['avg_answer_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ: {generation['avg_topic_coverage']:.1%}")
        print(f"  –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã: {generation['structured_answers_rate']:.1%}")
        print(f"  –î–æ–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞: {generation['avg_russian_ratio']:.1%}")
        
        print("\n‚ö° –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨")
        print("-" * 80)
        performance = metrics['performance']
        print(f"  –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {performance['avg_generation_time']:.2f}s")
        print(f"  –°—Ä–µ–¥–Ω–∏–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: {performance['avg_tokens_context']:.0f} —Ç–æ–∫–µ–Ω–æ–≤")
        
        print("\nüìÇ –ü–û –ö–ê–¢–ï–ì–û–†–ò–Ø–ú")
        print("-" * 80)
        for category, cat_metrics in metrics['by_category'].items():
            print(f"  {category.upper()} (n={cat_metrics['count']})")
            print(f"    ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞–π–¥–µ–Ω: {cat_metrics['source_found_rate']:.1%}")
            print(f"    ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤: {cat_metrics['avg_topic_coverage']:.1%}")
            print(f"    ‚Ä¢ –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {cat_metrics['avg_answer_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        
        print("\nüéØ –ü–û –°–õ–û–ñ–ù–û–°–¢–ò")
        print("-" * 80)
        for difficulty, diff_metrics in metrics['by_difficulty'].items():
            print(f"  {difficulty.upper()} (n={diff_metrics['count']})")
            print(f"    ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ –Ω–∞–π–¥–µ–Ω: {diff_metrics['source_found_rate']:.1%}")
            print(f"    ‚Ä¢ –ü–æ–∫—Ä—ã—Ç–∏–µ —Ç–æ–ø–∏–∫–æ–≤: {diff_metrics['avg_topic_coverage']:.1%}")
            print(f"    ‚Ä¢ –°—Ä–µ–¥–Ω–∏–π —Å–∫–æ—Ä: {diff_metrics['avg_score']:.3f}")
    
    def save_results(self, results: Dict[str, Any], output_path: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_path}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse
    
    parser = argparse.ArgumentParser(description='–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ RAG —Å–∏—Å—Ç–µ–º—ã')
    parser.add_argument('--dataset', type=str, default='tests/dataset.json', help='–ü—É—Ç—å –∫ –¥–∞—Ç–∞—Å–µ—Ç—É')
    parser.add_argument('--output', type=str, default='tests/evaluation_results.json', help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    parser.add_argument('--hyde', action='store_true', help='–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HyDE')
    parser.add_argument('--limit', type=int, default=None, help='–û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤')
    
    args = parser.parse_args()
    
    print("\nüöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è RAG —Å–∏—Å—Ç–µ–º—ã...")
    retriever = RAGRetriever()
    rag_service = RAGService(retriever)
    
    print("‚úÖ RAG —Å–∏—Å—Ç–µ–º–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞")
    
    # –°–æ–∑–¥–∞–µ–º evaluator
    evaluator = RAGEvaluator(retriever, rag_service)
    
    # –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–ø—Ä–æ—Å–æ–≤
    if args.limit:
        with open(args.dataset, 'r', encoding='utf-8') as f:
            dataset = json.load(f)
        dataset = dataset[:args.limit]
        temp_dataset_path = 'tests/dataset_limited.json'
        with open(temp_dataset_path, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)
        dataset_path = temp_dataset_path
    else:
        dataset_path = args.dataset
    
    # –û—Ü–µ–Ω–∏–≤–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    results = evaluator.evaluate_dataset(dataset_path, use_hyde=args.hyde)
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    evaluator.save_results(results, args.output)
    
    print("\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == '__main__':
    main()

