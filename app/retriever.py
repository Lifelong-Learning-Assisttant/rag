"""RAG Retriever —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Qdrant –∏ Redis"""
import tiktoken
from typing import List, Tuple
from langchain_core.documents import Document
from langchain_core.load import loads
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_qdrant import QdrantVectorStore, RetrievalMode
from langchain_qdrant.fastembed_sparse import FastEmbedSparse
from langchain_community.storage import RedisStore
from qdrant_client import QdrantClient

from app.config import settings
from llm_service.llm_client import LLMClient


class RAGRetriever:
    """Retriever –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Parent-Child —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏"""
    
    def __init__(self):
        self.encoding = tiktoken.get_encoding("cl100k_base")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self._init_embeddings()
        self._init_qdrant()
        self._init_redis()
        self._init_hyde_llm()
    
    def _init_embeddings(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è embedding –º–æ–¥–µ–ª–µ–π"""
        client = LLMClient(provider="openai")
        self.dense_embeddings = client.create_embeddings(
            model=settings.openai.embedding_model_name
        )
        self.sparse_embeddings = FastEmbedSparse(model_name="Qdrant/bm25")
    
    def _init_qdrant(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Qdrant –∫–ª–∏–µ–Ω—Ç–∞ –∏ vector store"""
        self.qdrant_client = QdrantClient(url=settings.qdrant.url)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏
        collections = self.qdrant_client.get_collections().collections
        collection_exists = any(
            c.name == settings.qdrant.collection_name for c in collections
        )
        
        if not collection_exists:
            raise ValueError(
                f"–ö–æ–ª–ª–µ–∫—Ü–∏—è '{settings.qdrant.collection_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –≤ Qdrant. "
                "–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø—É—Å—Ç–∏—Ç–µ ETL –ø—Ä–æ—Ü–µ—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö."
            )
        
        self.vector_store = QdrantVectorStore(
            client=self.qdrant_client,
            collection_name=settings.qdrant.collection_name,
            embedding=self.dense_embeddings,
            sparse_embedding=self.sparse_embeddings,
            retrieval_mode=RetrievalMode.HYBRID,
            vector_name="dense",  # –£–∫–∞–∑—ã–≤–∞–µ–º –∏–º—è dense –≤–µ–∫—Ç–æ—Ä–∞
            sparse_vector_name="sparse",  # –£–∫–∞–∑—ã–≤–∞–µ–º –∏–º—è sparse –≤–µ–∫—Ç–æ—Ä–∞
        )
    
    def _init_redis(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis store –¥–ª—è parent chunks"""
        self.parent_store = RedisStore(
            redis_url=settings.redis.url,
            namespace="rag:parents"
        )
    
    def _init_hyde_llm(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è LLM –¥–ª—è HyDE"""
        client = LLMClient(provider="openai")
        self.hyde_llm = client.create_chat(
            model=settings.openai.chat_model_name,
            temperature=0.7,  # –í—ã—à–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –¥–ª—è —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏—è
        )
        
        # –ü—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞
        hyde_template = """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é –∏ data science.

–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞–¥–∞–ª –≤–æ–ø—Ä–æ—Å: {question}

–ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–∏–π, –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–π –ø–∞—Ä–∞–≥—Ä–∞—Ñ (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), –∫–æ—Ç–æ—Ä—ã–π –º–æ–≥ –±—ã –±—ã—Ç—å –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å –∏–∑ —É—á–µ–±–Ω–∏–∫–∞ –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é. 
–ü–∏—à–∏ —Ç–∞–∫, –∫–∞–∫ –±—É–¥—Ç–æ —ç—Ç–æ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω–∏–∫–∞ –Ø–Ω–¥–µ–∫—Å–∞ –ø–æ ML.
–ò—Å–ø–æ–ª—å–∑—É–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.
–ù–ï –ø–∏—à–∏ "–û—Ç–≤–µ—Ç:", –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ —Å–∞–º —Ç–µ–∫—Å—Ç.

–ì–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞:"""

        self.hyde_prompt = ChatPromptTemplate.from_template(hyde_template)
        self.hyde_chain = self.hyde_prompt | self.hyde_llm | StrOutputParser()
    
    def _generate_hypothetical_document(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞"""
        try:
            hypothetical_doc = self.hyde_chain.invoke({"question": query})
            print(f"üîÆ HyDE –¥–æ–∫—É–º–µ–Ω—Ç: {hypothetical_doc[:100]}...")
            return hypothetical_doc
        except Exception as e:
            print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ HyDE –¥–æ–∫—É–º–µ–Ω—Ç–∞: {e}")
            return query  # Fallback –Ω–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∑–∞–ø—Ä–æ—Å
    
    def _tiktoken_len(self, text: str) -> int:
        """–ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ"""
        return len(self.encoding.encode(text))
    
    def _load_parent_chunk(self, parent_id: str) -> Document | None:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å parent chunk –∏–∑ Redis"""
        try:
            result = self.parent_store.mget([parent_id])
            if result and result[0]:
                return loads(result[0].decode("utf-8"))
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ parent chunk {parent_id}: {e}")
        return None
    
    def get_parent_docs_count(self) -> int:
        """–ü–æ–ª—É—á–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ parent –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ Redis"""
        try:
            count = 0
            # yield_keys –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Ç–µ—Ä–∞—Ç–æ—Ä –ø–æ –∫–ª—é—á–∞–º —Å –ø—Ä–µ—Ñ–∏–∫—Å–æ–º
            for _ in self.parent_store.yield_keys():
                count += 1
            return count
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–¥—Å—á–µ—Ç–∞ –∫–ª—é—á–µ–π Redis: {e}")
            return 0
    
    def search(
        self,
        query: str,
        top_k: int | None = None,
        max_tokens: int | None = None
    ) -> List[Document]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ (parent chunks)
        """
        if top_k is None:
            top_k = settings.rag.retrieval_top_k
        if max_tokens is None:
            max_tokens = settings.rag.max_context_tokens
        
        # –ü–æ–∏—Å–∫ child chunks –≤ Qdrant
        child_chunks = self.vector_store.similarity_search(query, k=top_k)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ parent chunks –∏–∑ Redis
        parent_ids = []
        for child in child_chunks:
            parent_id = child.metadata.get("parent_id")
            if parent_id and parent_id not in parent_ids:
                parent_ids.append(parent_id)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ parent chunks
        parent_chunks = []
        total_tokens = 0
        
        for parent_id in parent_ids:
            parent = self._load_parent_chunk(parent_id)
            if parent:
                chunk_tokens = self._tiktoken_len(parent.page_content)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
                if total_tokens + chunk_tokens > max_tokens:
                    break
                
                parent_chunks.append(parent)
                total_tokens += chunk_tokens
        
        return parent_chunks
    
    def search_with_scores(
        self,
        query: str,
        top_k: int | None = None,
        max_tokens: int | None = None
    ) -> List[Tuple[Document, float]]:
        """
        –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å–æ —Å–∫–æ—Ä–∞–º–∏
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–∫)
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–¥–æ–∫—É–º–µ–Ω—Ç, —Å–∫–æ—Ä)
        """
        if top_k is None:
            top_k = settings.rag.retrieval_top_k
        if max_tokens is None:
            max_tokens = settings.rag.max_context_tokens
        
        # –ü–æ–∏—Å–∫ child chunks –≤ Qdrant —Å–æ —Å–∫–æ—Ä–∞–º–∏
        child_chunks_with_scores = self.vector_store.similarity_search_with_score(query, k=top_k)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å parent_id -> –ª—É—á—à–∏–π —Å–∫–æ—Ä
        parent_scores = {}
        parent_ids_order = []
        
        for child, score in child_chunks_with_scores:
            parent_id = child.metadata.get("parent_id")
            if parent_id:
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à–∏–π (–º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –¥–ª—è distance) —Å–∫–æ—Ä –¥–ª—è –∫–∞–∂–¥–æ–≥–æ parent
                if parent_id not in parent_scores:
                    parent_scores[parent_id] = score
                    parent_ids_order.append(parent_id)
                else:
                    parent_scores[parent_id] = min(parent_scores[parent_id], score)
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ parent chunks —Å–æ —Å–∫–æ—Ä–∞–º–∏
        parent_chunks_with_scores = []
        total_tokens = 0
        
        for parent_id in parent_ids_order:
            parent = self._load_parent_chunk(parent_id)
            if parent:
                chunk_tokens = self._tiktoken_len(parent.page_content)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–º–∏—Ç —Ç–æ–∫–µ–Ω–æ–≤
                if total_tokens + chunk_tokens > max_tokens:
                    break
                
                parent_chunks_with_scores.append((parent, parent_scores[parent_id]))
                total_tokens += chunk_tokens
        
        return parent_chunks_with_scores
    
    def search_with_hyde(
        self,
        query: str,
        top_k: int | None = None,
        max_tokens: int | None = None,
        score_threshold: float | None = None
    ) -> List[Tuple[Document, float]]:
        """
        –ü–æ–∏—Å–∫ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º HyDE
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            max_tokens: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
            score_threshold: –ü–æ—Ä–æ–≥ —Å–∫–æ—Ä–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (–¥–æ–∫—É–º–µ–Ω—Ç, —Å–∫–æ—Ä)
        """
        if top_k is None:
            top_k = settings.rag.retrieval_top_k
        if max_tokens is None:
            max_tokens = settings.rag.max_context_tokens
        if score_threshold is None:
            score_threshold = settings.rag.score_threshold
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –¥–æ–∫—É–º–µ–Ω—Ç
        search_query = self._generate_hypothetical_document(query)
        
        # –ü–æ–∏—Å–∫ child chunks –≤ Qdrant —Å–æ —Å–∫–æ—Ä–∞–º–∏
        child_chunks_with_scores = self.vector_store.similarity_search_with_score(
            search_query, k=top_k * 2  # –ë–µ—Ä—ë–º –±–æ–ª—å—à–µ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        )
        
        # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å parent_id -> –ª—É—á—à–∏–π —Å–∫–æ—Ä
        parent_scores = {}
        parent_ids_order = []
        
        for child, score in child_chunks_with_scores:
            # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –ø–æ—Ä–æ–≥—É —Å–∫–æ—Ä–∞
            if score > score_threshold:
                continue
                
            parent_id = child.metadata.get("parent_id")
            if parent_id:
                if parent_id not in parent_scores:
                    parent_scores[parent_id] = score
                    parent_ids_order.append(parent_id)
                else:
                    parent_scores[parent_id] = min(parent_scores[parent_id], score)
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ top_k
        parent_ids_order = parent_ids_order[:top_k]
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ parent chunks —Å–æ —Å–∫–æ—Ä–∞–º–∏
        parent_chunks_with_scores = []
        total_tokens = 0
        
        for parent_id in parent_ids_order:
            parent = self._load_parent_chunk(parent_id)
            if parent:
                chunk_tokens = self._tiktoken_len(parent.page_content)
                
                if total_tokens + chunk_tokens > max_tokens:
                    break
                
                parent_chunks_with_scores.append((parent, parent_scores[parent_id]))
                total_tokens += chunk_tokens
        
        return parent_chunks_with_scores
    
    def get_context_for_query(self, query: str, top_k: int | None = None, with_scores: bool = False, use_hyde: bool = False) -> dict:
        """
        –ü–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        
        Args:
            query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
            top_k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            with_scores: –í–∫–ª—é—á–∏—Ç—å —Å–∫–æ—Ä—ã –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            use_hyde: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å HyDE –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–∏—Å–∫–∞
        
        Returns:
            dict —Å –ø–æ–ª—è–º–∏:
                - query: –∏—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
                - documents: —Å–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
                - scores: —Å–ø–∏—Å–æ–∫ —Å–∫–æ—Ä–æ–≤ (–µ—Å–ª–∏ with_scores=True)
                - total_tokens: –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤
                - sources: —Å–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
                - used_hyde: –±—ã–ª –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω HyDE
        """
        if use_hyde:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º HyDE –ø–æ–∏—Å–∫ (–≤—Å–µ–≥–¥–∞ —Å–æ —Å–∫–æ—Ä–∞–º–∏)
            documents_with_scores = self.search_with_hyde(query, top_k=top_k)
            documents = [doc for doc, _ in documents_with_scores]
            scores = [score for _, score in documents_with_scores] if with_scores else None
        elif with_scores:
            documents_with_scores = self.search_with_scores(query, top_k=top_k)
            documents = [doc for doc, _ in documents_with_scores]
            scores = [score for _, score in documents_with_scores]
        else:
            documents = self.search(query, top_k=top_k)
            scores = None
        
        total_tokens = sum(self._tiktoken_len(doc.page_content) for doc in documents)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources = []
        seen_files = set()
        for doc in documents:
            filename = doc.metadata.get("filename", "unknown")
            if filename not in seen_files:
                sources.append({
                    "filename": filename,
                    "breadcrumbs": doc.metadata.get("breadcrumbs", ""),
                    "url": doc.metadata.get("url", "")
                })
                seen_files.add(filename)
        
        result = {
            "query": query,
            "documents": documents,
            "total_tokens": total_tokens,
            "sources": sources,
            "num_documents": len(documents),
            "used_hyde": use_hyde
        }
        
        if with_scores:
            result["scores"] = scores
        
        return result

